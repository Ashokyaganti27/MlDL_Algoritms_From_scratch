
# Project Overview: Machine Learning Algorithms from Scratch

This repository is a hands-on, no-black-box implementation of core machine learning algorithms from scratch (without libraries like scikit-learn or TensorFlow). The goal is to learn how ML works by building every component manuallyâ€”from gradient descent to backpropagationâ€”with clear, documented code.

ðŸ“Œ Algorithms Implemented (Current/Future)

## **Supervised Learning**

*** Linear Regression (Gradient Descent)**

ðŸ“Œ Whatâ€™s Implemented?

--- Manual computation of predictions (y_hat)

--- Mean Squared Error (MSE) loss function

--- Gradient calculation for weights (m) and bias (c)

--- Parameter updates using gradient descent

--- Early stopping mechanism using loss convergence check

---Logging each step to visualize learning behavior

## Linear Regression completed

## Next

- Logistic Regression
- Perceptron
- Decision Trees
- k-Nearest Neighbors (kNN)

## **Optimization**

- Batch Gradient Descent
- Stochastic GD
- Momentum, Adam

## **Unsupervised Learning**

- k-Means Clustering
- PCA (Dimensionality Reduction)

## Author

Ashok â€” learning and building Machine Learning algorithms from first principles.
